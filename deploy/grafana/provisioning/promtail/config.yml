# ═══════════════════════════════════════════════════════════════════
# Promtail Configuration для сбора логов
# ═══════════════════════════════════════════════════════════════════
# Собирает логи из Docker/Podman контейнеров и отправляет в VictoriaLogs
#
# Sources:
# 1. Docker containers (через Docker API)
# 2. System logs (опционально)
#
# Target: VictoriaLogs (Loki-compatible API)
# ═══════════════════════════════════════════════════════════════════

# Server config
server:
  http_listen_port: 9080
  grpc_listen_port: 0
  log_level: info

# Positions (для отслеживания прочитанных логов)
positions:
  filename: /tmp/positions.yaml

# Clients (куда отправлять логи)
clients:
  # VictoriaLogs (Loki-compatible endpoint)
  - url: ${VICTORIALOGS_URL}
    # Batching config (оптимизация)
    batchwait: 1s
    batchsize: 1048576  # 1MB
    # Timeout
    timeout: 10s
    # Backoff config при ошибках
    backoff_config:
      min_period: 500ms
      max_period: 5m
      max_retries: 10
    # External labels (добавляются ко всем логам)
    external_labels:
      cluster: pressograph
      environment: development

# Scrape configs (откуда собирать логи)
scrape_configs:
  # ─────────────────────────────────────────────────────────────────
  # Docker Containers Log Collection
  # ─────────────────────────────────────────────────────────────────
  - job_name: docker
    docker_sd_configs:
      - host: unix:///var/run/docker.sock
        refresh_interval: 5s
        filters:
          # Собирать логи со всех контейнеров (можно фильтровать)
          - name: label
            values: []

    # Relabeling (извлечение metadata из Docker)
    relabel_configs:
      # Container name
      - source_labels: ['__meta_docker_container_name']
        regex: '/(.*)'
        target_label: 'container'

      # Container ID (короткий)
      - source_labels: ['__meta_docker_container_id']
        regex: '(.{12}).*'
        target_label: 'container_id'

      # Docker Compose service name
      - source_labels: ['__meta_docker_container_label_com_docker_compose_service']
        target_label: 'service'

      # Docker Compose project
      - source_labels: ['__meta_docker_container_label_com_docker_compose_project']
        target_label: 'project'

      # Pressograph environment (если есть label)
      - source_labels: ['__meta_docker_container_label_com_pressograph_environment']
        target_label: 'environment'

      # Pressograph service type
      - source_labels: ['__meta_docker_container_label_com_pressograph_service']
        target_label: 'service_type'

      # Image name
      - source_labels: ['__meta_docker_container_label_org_opencontainers_image_title']
        target_label: 'image_title'

      # Container network
      - source_labels: ['__meta_docker_network_name']
        target_label: 'network'

    # Pipeline stages (обработка логов)
    pipeline_stages:
      # Stage 1: JSON parsing (если логи в JSON формате)
      - json:
          expressions:
            level: level
            timestamp: timestamp
            message: message
            trace_id: trace_id
            span_id: span_id
            service: service
            error: error

      # Stage 2: Timestamp extraction
      - timestamp:
          source: timestamp
          format: RFC3339Nano
          fallback_formats:
            - RFC3339
            - '2006-01-02T15:04:05.000Z'
            - '2006-01-02 15:04:05'

      # Stage 3: Labels extraction (для фильтрации)
      - labels:
          level:
          service:
          trace_id:
          error:

      # Stage 4: Output formatting
      - output:
          source: message

      # Stage 5: Metrics generation (опционально)
      - metrics:
          log_lines_total:
            type: Counter
            description: "Total number of log lines"
            source: level
            config:
              action: inc
          log_bytes_total:
            type: Counter
            description: "Total bytes of logs"
            source: message
            config:
              action: add
              value: "{{len .Value}}"

  # ─────────────────────────────────────────────────────────────────
  # Pressograph Backend Logs (специфичная обработка)
  # ─────────────────────────────────────────────────────────────────
  - job_name: pressograph-backend
    docker_sd_configs:
      - host: unix:///var/run/docker.sock
        refresh_interval: 5s
        filters:
          - name: label
            values: ['com.pressograph.service=backend']

    relabel_configs:
      - source_labels: ['__meta_docker_container_name']
        regex: '/(.*)'
        target_label: 'container'
      - source_labels: ['__meta_docker_container_label_com_pressograph_environment']
        target_label: 'environment'

    pipeline_stages:
      # JSON parsing для structured logs
      - json:
          expressions:
            level: level
            msg: msg
            timestamp: timestamp
            trace_id: trace_id
            span_id: span_id
            method: method
            path: path
            status_code: status_code
            duration: duration
            error: error
            stack: stack

      # Timestamp
      - timestamp:
          source: timestamp
          format: RFC3339Nano

      # Labels
      - labels:
          level:
          method:
          status_code:
          trace_id:

      # Output (форматирование сообщения)
      - template:
          source: output
          template: '{{ if .error }}[ERROR] {{ .msg }}: {{ .error }}{{ else }}{{ .msg }}{{ end }}'

      - output:
          source: output

  # ─────────────────────────────────────────────────────────────────
  # PostgreSQL Logs (из контейнера)
  # ─────────────────────────────────────────────────────────────────
  - job_name: postgres
    docker_sd_configs:
      - host: unix:///var/run/docker.sock
        refresh_interval: 5s
        filters:
          - name: label
            values: ['com.pressograph.service=database']

    relabel_configs:
      - source_labels: ['__meta_docker_container_name']
        regex: '/(.*)'
        target_label: 'container'
      - target_label: 'service'
        replacement: 'postgres'

    pipeline_stages:
      # PostgreSQL log format parsing
      - regex:
          expression: '^(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\.\d{3}) (?P<timezone>\w+) \[(?P<pid>\d+)\] (?P<level>\w+):\s+(?P<message>.+)$'

      - timestamp:
          source: timestamp
          format: '2006-01-02 15:04:05.000'

      - labels:
          level:
          pid:

      - output:
          source: message

# ═══════════════════════════════════════════════════════════════════
# NOTES
# ═══════════════════════════════════════════════════════════════════
#
# 1. VictoriaLogs URL:
#    Передается через environment variable VICTORIALOGS_URL
#    Формат: http://victorialogs:9428/insert/jsonline
#
# 2. JSON Logs в Backend:
#    Используйте structured logging библиотеку:
#    - pino (рекомендуется для Node.js)
#    - winston (популярная альтернатива)
#
#    Пример с pino:
#    ```javascript
#    const pino = require('pino');
#    const logger = pino({
#      level: 'info',
#      formatters: {
#        level: (label) => ({ level: label })
#      },
#      timestamp: pino.stdTimeFunctions.isoTime
#    });
#
#    logger.info({ method: 'GET', path: '/api/users', status_code: 200 }, 'Request completed');
#    ```
#
# 3. Trace ID:
#    Добавьте trace_id в логи для correlation с трейсами
#    Используйте OpenTelemetry Context API
#
# 4. Log Levels:
#    Стандартные levels: debug, info, warn, error, fatal
#    Используйте в labels для фильтрации в Grafana
#
# 5. Filtering Logs:
#    В Grafana используйте LogQL:
#    {service="pressograph-backend"} |= "error"
#    {level="error"} | json | status_code >= 500
#
# 6. Performance:
#    - batchwait и batchsize настроены для оптимальной производительности
#    - Увеличьте batchsize для high-volume логов
#    - positions.yaml сохраняет прогресс (не потеряются логи при рестарте)
#
# ═══════════════════════════════════════════════════════════════════
