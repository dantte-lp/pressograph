<?xml version="1.0"?>
<!--
  ClickHouse Configuration for Uptrace
  Optimized for OLAP workload with telemetry data (traces, metrics, logs)
-->
<clickhouse>
    <!-- Logging configuration for ClickHouse -->
    <logger>
        <level>information</level>
        <log>/var/log/clickhouse-server/clickhouse-server.log</log>
        <errorlog>/var/log/clickhouse-server/clickhouse-server.err.log</errorlog>
        <size>1000M</size>
        <count>10</count>
        <console>0</console>
    </logger>

    <!-- Network Configuration -->
    <http_port>8123</http_port>
    <tcp_port>9000</tcp_port>
    <listen_host>0.0.0.0</listen_host>

    <!-- Connection & Performance settings -->
    <max_connections>1024</max_connections>
    <max_concurrent_queries>100</max_concurrent_queries>
    <max_server_memory_usage_to_ram_ratio>0.8</max_server_memory_usage_to_ram_ratio>

    <!-- Thread Pool -->
    <max_thread_pool_size>10000</max_thread_pool_size>
    <max_io_thread_pool_size>100</max_io_thread_pool_size>

    <!-- Compression -->
    <compression>
        <case>
            <min_part_size>10485760</min_part_size>
            <min_part_size_ratio>0.01</min_part_size_ratio>
            <method>zstd</method>
            <level>3</level>
        </case>
    </compression>

    <!-- Merge tree settings for time-series data -->
    <merge_tree>
        <max_suspicious_broken_parts>5</max_suspicious_broken_parts>
        <max_bytes_to_merge_at_max_space_in_pool>161061273600</max_bytes_to_merge_at_max_space_in_pool>
        <max_replicated_merges_in_queue>16</max_replicated_merges_in_queue>
        <parts_to_throw_insert>300</parts_to_throw_insert>
        <parts_to_delay_insert>150</parts_to_delay_insert>
        <min_rows_for_wide_part>100000</min_rows_for_wide_part>
        <min_bytes_for_wide_part>10485760</min_bytes_for_wide_part>
    </merge_tree>

    <!-- Query cache settings -->
    <query_cache>
        <max_size_in_bytes>1073741824</max_size_in_bytes>
        <max_entries>1024</max_entries>
        <max_entry_size_in_bytes>1048576</max_entry_size_in_bytes>
    </query_cache>

    <!-- Query Log (for monitoring) -->
    <query_log>
        <database>system</database>
        <table>query_log</table>
        <partition_by>toYYYYMM(event_date)</partition_by>
        <ttl>event_date + INTERVAL 30 DAY</ttl>
        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
    </query_log>

    <!-- Metric Log -->
    <metric_log>
        <database>system</database>
        <table>metric_log</table>
        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
        <collect_interval_milliseconds>1000</collect_interval_milliseconds>
    </metric_log>

    <!-- Background Task Limits -->
    <background_pool_size>16</background_pool_size>
    <background_schedule_pool_size>16</background_schedule_pool_size>
    <background_fetches_pool_size>8</background_fetches_pool_size>
    <background_move_pool_size>8</background_move_pool_size>

    <!-- Profiles for query optimization -->
    <profiles>
        <default>
            <max_execution_time>30</max_execution_time>
            <max_memory_usage>10000000000</max_memory_usage>  <!-- 10GB -->
            <max_bytes_before_external_group_by>5000000000</max_bytes_before_external_group_by>  <!-- 5GB -->
            <max_threads>8</max_threads>
            <optimize_read_in_order>1</optimize_read_in_order>
            <optimize_aggregation_in_order>1</optimize_aggregation_in_order>
        </default>
    </profiles>

    <!-- Users (Uptrace user added in docker compose environment) -->
    <users>
        <default>
            <password></password>
            <networks><ip>::/0</ip></networks>
            <profile>default</profile>
            <quota>default</quota>
        </default>
    </users>

    <!-- Data paths -->
    <path>/var/lib/clickhouse/</path>
    <tmp_path>/var/lib/clickhouse/tmp/</tmp_path>
    <user_files_path>/var/lib/clickhouse/user_files/</user_files_path>

    <!-- Timezone -->
    <timezone>UTC</timezone>
</clickhouse>
